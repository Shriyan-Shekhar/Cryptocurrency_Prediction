{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Preprocessing and Feature Creation\n","\n","Data Processing and Feature Engineering is performed in the following, using the given variables downloaded from the Binance API, we will calculate the following:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:34:36.072035Z","iopub.status.busy":"2024-11-14T14:34:36.071639Z","iopub.status.idle":"2024-11-14T14:34:51.280385Z","shell.execute_reply":"2024-11-14T14:34:51.279226Z","shell.execute_reply.started":"2024-11-14T14:34:36.071998Z"},"trusted":true},"outputs":[],"source":["!pip install ta"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:35:00.389290Z","iopub.status.busy":"2024-11-14T14:35:00.388915Z","iopub.status.idle":"2024-11-14T14:35:05.908645Z","shell.execute_reply":"2024-11-14T14:35:05.907534Z","shell.execute_reply.started":"2024-11-14T14:35:00.389252Z"},"trusted":true},"outputs":[],"source":["import torch\n","from ta.momentum import rsi\n","from ta.trend import macd\n","import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.preprocessing import MinMaxScaler\n","from ta import add_all_ta_features\n","from ta.volatility import BollingerBands\n","from ta.momentum import RSIIndicator, StochasticOscillator\n","from ta.trend import EMAIndicator, MACD\n","from ta.volume import VolumeWeightedAveragePrice\n","\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","print(device)\n","\n","# Directory containing .csv files of cryptocurrency data\n","directory = '/kaggle/input/crypto-2021-10-01-1hour'\n","dataframes = []\n","\n","for filename in os.listdir(directory):\n","    if filename.endswith('.csv') and filename != \"USDCUSDT1h.csv\" and filename != \"DAIUSDT1h.csv\":\n","        ticker = filename[:-6] # Remove the '1h.csv' or '1d.csv' extension\n","        data = pd.read_csv(os.path.join(directory, filename), parse_dates=['time'])\n","\n","        cutoff_date = pd.Timestamp('2021-10-01')\n","\n","        if data['time'].iloc[0] > cutoff_date:\n","            print(f\"Skipping {ticker}: first entry is after cutoff date.\")\n","            continue  # Skip this dataset\n","            \n","        data = data[data['time'] >= cutoff_date]\n","\n","        windows = [5, 10, 20]\n","        data[\"NormClose\"] = (data[\"close\"] - data[\"close\"].mean()) / data[\"close\"].std()\n","        data[\"DailyLogReturn\"] = np.log(1 + data[\"close\"].pct_change())\n","\n","        data['volume_quote_ratio'] = data['volume'] / data['quote_volume']\n","        data['buy_sell_volume_ratio'] = data['buy_base_vol'] / data['volume']\n","        data['buy_sell_quote_ratio'] = data['buy_quote_vol'] / data['quote_volume']\n","\n","        # Stochastic Oscillator\n","        stoch = StochasticOscillator(high = data['high'], low = data['low'], close = data['close'])\n","        data['stoch_k'] = stoch.stoch()\n","        data['stoch_d'] = stoch.stoch_signal()\n","\n","        # VWAP\n","        vwap = VolumeWeightedAveragePrice(high = data['high'], low = data['low'],\n","                                         close = data['close'], volume = data['volume'])\n","        data['vwap'] = vwap.volume_weighted_average_price()\n","\n","        for window in windows:\n","            # Parkinson Volatility\n","            data[f'parkinson_vol_{window}'] = np.sqrt(\n","                (1.0 / (4.0 * np.log(2.0))) *\n","                (np.log(data['high'] / data['low']) ** 2).rolling(window).mean()\n","            )\n","\n","            # Garman-Klass Volatility\n","            data[f'garman_klass_vol_{window}'] = np.sqrt(\n","                (0.5 * np.log(data['high'] / data['low']) ** 2) -\n","                (2.0 * np.log(2.0) - 1.0) * (np.log(data['close'] / data['open']) ** 2)\n","            ).rolling(window).mean()\n","\n","        data['avg_trade_size'] = data['volume'] / data['trades']\n","        data['avg_trade_quote_size'] = data['quote_volume'] / data['trades']\n","        data[\"Ticker\"] = ticker\n","        data.set_index('time', inplace = True)\n","        data.drop(columns = [\"open\", \"low\", \"high\", \"volume\", \"buy_base_vol\", \"quote_volume\", \"trades\", \"buy_quote_vol\"], inplace=True)\n","        \n","        if data.empty:\n","            print(f\"Warning: {ticker} DataFrame is empty.\")\n","            continue\n","\n","        dataframes.append(data)\n","        \n","# Concatenate all DataFrames into a single DataFrame with a hierarchical index\n","all_data = pd.concat(dataframes, keys=[df['Ticker'][0] for df in dataframes])\n","\n","# level_0_index = 'OMUSDT'  # Replace with your actual level 0 index value\n","\n","# # Filter the DataFrame for the specific level 0 index\n","# filtered_data = all_data.loc[level_0_index]\n","\n","# # Find rows with missing/NaN values\n","# missing_data = filtered_data[filtered_data.isna().any(axis=1)]\n","\n","# Drop any rows with missing values and filter time range\n","all_data = all_data.dropna()\n","all_data = all_data.loc['2021-10-01':]\n","\n","# Specify the level 1 index you want to delete\n","level_1_index_to_delete = pd.Timestamp('2023-06-08 23:00:00')\n","\n","# Drop the specified level 1 index across all level 0 indexes\n","all_data = all_data.drop(level_1_index_to_delete, level=1, errors='ignore')\n","\n","# Display the combined DataFrame\n","all_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:35:05.911391Z","iopub.status.busy":"2024-11-14T14:35:05.911024Z","iopub.status.idle":"2024-11-14T14:35:06.026259Z","shell.execute_reply":"2024-11-14T14:35:06.025120Z","shell.execute_reply.started":"2024-11-14T14:35:05.911354Z"},"trusted":true},"outputs":[],"source":["row_counts = all_data.groupby(level=0).size()\n","\n","# Print the number of rows for each level 0 index (make sure they are all the same)\n","print(row_counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:35:06.027994Z","iopub.status.busy":"2024-11-14T14:35:06.027601Z","iopub.status.idle":"2024-11-14T14:35:06.491904Z","shell.execute_reply":"2024-11-14T14:35:06.490738Z","shell.execute_reply.started":"2024-11-14T14:35:06.027953Z"},"trusted":true},"outputs":[],"source":["# Print the first row of every currency\n","first_rows = all_data.reset_index(level=1).groupby(level=0).first()\n","\n","first_rows"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:35:27.040052Z","iopub.status.busy":"2024-11-14T14:35:27.039236Z","iopub.status.idle":"2024-11-14T14:35:27.858674Z","shell.execute_reply":"2024-11-14T14:35:27.857749Z","shell.execute_reply.started":"2024-11-14T14:35:27.040000Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","\n","plt.figure(figsize=(10, 5))\n","tickers = all_data.index.get_level_values(0).unique()\n","selected_tickers = np.random.choice(tickers, size=10, replace=False)\n","\n","for ticker in selected_tickers:\t\n","    plt.plot(all_data.loc[ticker].index,              \n","             np.cumsum(all_data.loc[ticker][\"DailyLogReturn\"]),              \n","             label=f'{ticker}')\n","    \n","plt.title(\"Evolution of Ten Cryptocurrencies\")\n","plt.xlabel('Date')\n","plt.gca().tick_params(axis='x', rotation=45)\n","plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval = 4))\n","plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n","plt.ylabel('Cumulative Log Return')\n","plt.legend(ncol=2, loc=\"lower right\", prop={'size': 8, 'family': 'serif'})\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Correlation between Cryptocurrency\n","\n","Computing the correlation between currencies to initialise the edges for the graph. Current method utilises a date range to compute correlation (2023-10-01 to 2024-10-01). Preferably, we would use fundamental information about each currency for correlation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:35:51.002914Z","iopub.status.busy":"2024-11-14T14:35:51.002315Z","iopub.status.idle":"2024-11-14T14:35:51.499099Z","shell.execute_reply":"2024-11-14T14:35:51.498142Z","shell.execute_reply.started":"2024-11-14T14:35:51.002875Z"},"trusted":true},"outputs":[],"source":["df_close = all_data.copy()\n","\n","# Reset the index to access the time column\n","df_close.reset_index(inplace=True)\n","df_close = df_close[[\"time\", \"Ticker\", \"close\"]]\n","df_close[\"time\"] = pd.to_datetime(df_close[\"time\"])\n","df_close.set_index(\"time\", inplace=True) \n","\n","# Sort the DataFrame by index to ensure it is monotonic\n","df_close.sort_index(inplace=True)\n","df_close[\"close\"] = np.log(df_close[\"close\"])\n","\n","# Filter for dates in 2024\n","df_close_filtered = df_close.loc['2024-01-01':'2024-10-01']\n","df_close_filtered.reset_index(inplace=True) \n","\n","# Create a pivot table to reshape the DataFrame\n","df_close_filtered = pd.pivot_table(    \n","    df_close_filtered, \n","    values=\"close\", \n","    columns=\"Ticker\", \n","    index=\"time\")\n","\n","df_close_filtered"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:35:54.614524Z","iopub.status.busy":"2024-11-14T14:35:54.614120Z","iopub.status.idle":"2024-11-14T14:35:57.871908Z","shell.execute_reply":"2024-11-14T14:35:57.870957Z","shell.execute_reply.started":"2024-11-14T14:35:54.614476Z"},"trusted":true},"outputs":[],"source":["import seaborn as sns\n","\n","correlation_matrix = df_close_filtered.diff().corr()\n","correlation_matrix = (correlation_matrix - (correlation_matrix == 1)) # Drop Self-Correlation\n","\n","plt.figure(figsize=(15, 15))\n","\n","sns.heatmap(correlation_matrix,            \n","            linewidths=.5,            \n","            annot=True,            \n","            square=True,            \n","            cmap=\"viridis\")\n","\n","plt.xlabel(\"Cryptocurrency\")\n","plt.ylabel(\"Cryptocurrency\")\n","plt.title(\"Correlation Matrix between each Cryptocurrency\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:36:01.742819Z","iopub.status.busy":"2024-11-14T14:36:01.742060Z","iopub.status.idle":"2024-11-14T14:36:02.345798Z","shell.execute_reply":"2024-11-14T14:36:02.344904Z","shell.execute_reply.started":"2024-11-14T14:36:01.742777Z"},"trusted":true},"outputs":[],"source":["import networkx as nx\n","correlation_matrix_np = correlation_matrix.to_numpy()\n","adj_correlation_matrix = (correlation_matrix_np * (abs(correlation_matrix_np) > .7).astype(int)) # Threshold to form edge (0.7)\n","correlation_matrix_graph = nx.from_numpy_array(adj_correlation_matrix)\n","correlation_matrix_graph = nx.relabel_nodes(correlation_matrix_graph, dict(enumerate(correlation_matrix.index)))\n","\n","plt.figure(figsize=(12, 12))\n","\n","nx.draw(correlation_matrix_graph, \n","        with_labels=True, \n","        node_size=100, \n","        node_color='skyblue', \n","        font_size=8, \n","        font_weight='bold', \n","        font_color='black', \n","        pos=nx.spring_layout(correlation_matrix_graph))\n","\n","plt.title('Crypto Graph by Historical Correlation')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:36:19.746995Z","iopub.status.busy":"2024-11-14T14:36:19.746416Z","iopub.status.idle":"2024-11-14T14:36:19.754825Z","shell.execute_reply":"2024-11-14T14:36:19.753855Z","shell.execute_reply.started":"2024-11-14T14:36:19.746959Z"},"trusted":true},"outputs":[],"source":["adj_correlation_matrix"]},{"cell_type":"markdown","metadata":{},"source":["# Building PyTorch Geometric Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:36:22.294656Z","iopub.status.busy":"2024-11-14T14:36:22.294264Z","iopub.status.idle":"2024-11-14T14:36:35.424394Z","shell.execute_reply":"2024-11-14T14:36:35.423400Z","shell.execute_reply.started":"2024-11-14T14:36:22.294617Z"},"trusted":true},"outputs":[],"source":["!pip install torch_geometric"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:36:48.260070Z","iopub.status.busy":"2024-11-14T14:36:48.258919Z","iopub.status.idle":"2024-11-14T14:36:48.389925Z","shell.execute_reply":"2024-11-14T14:36:48.388984Z","shell.execute_reply.started":"2024-11-14T14:36:48.260027Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch_geometric.data import Data\n","\n","nodes_nb = len(adj_correlation_matrix)\n"," \n","x = torch.tensor(\n","\tall_data.drop(columns=[\"Ticker\", \"close\"]).to_numpy().reshape((nodes_nb, -1, all_data.shape[1] - 2)), dtype=torch.float32).to(device)  # shape (nodes_nb, timestamps_nb, features_nb) Note: This won't work if they are not integers\n","x = x.transpose(1, 2)  # shape (nodes_nb, features_nb, timestamps_nb)\n","\n","close_prices = torch.tensor(\n","\t\tall_data[[\"close\"]].to_numpy().reshape((nodes_nb, -1)), dtype=torch.float32\n","\t).to(device)\n","\n","edge_nb = np.count_nonzero(adj_correlation_matrix)\n","edge_index, edge_weight = torch.zeros((2, edge_nb), dtype=torch.long).to(device), torch.zeros((edge_nb,), dtype=torch.float32).to(device)\n","count = 0\n","for i in range(nodes_nb):\n","\t\tfor j in range(nodes_nb):\n","\t\t\tif (weight := adj_correlation_matrix[i, j]) != 0:\n","\t\t\t\tedge_index[0, count], edge_index[1, count] = i, j\n","\t\t\t\tedge_weight[count] = weight\n","\t\t\t\tcount += 1\n","\n","x.shape, edge_index.shape, edge_weight.shape"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:36:54.040516Z","iopub.status.busy":"2024-11-14T14:36:54.040117Z","iopub.status.idle":"2024-11-14T14:36:57.515395Z","shell.execute_reply":"2024-11-14T14:36:57.514383Z","shell.execute_reply.started":"2024-11-14T14:36:54.040473Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Data(x=[34, 16, 25], edge_index=[2, 208], y=[34, 1], edge_weight=[208], close_price=[34, 25], close_price_y=[34, 1])\n"]}],"source":["past_window, future_window = 25, 1\n","timestamps = [\n","\t\t\tData(\n","\t\t\t\tx = x[:, :, idx:idx + past_window],\n","\t\t\t\tedge_index = edge_index,\n","\t\t\t\tedge_weight = edge_weight,\n","\t\t\t\tclose_price = close_prices[:, idx:idx + past_window],\n","\t\t\t\ty = x[:, 0, idx + past_window:idx + past_window + future_window],\n","\t\t\t\tclose_price_y=close_prices[:, idx + past_window:idx + past_window + future_window],\n","\t\t\t).to(device) for idx in range(x.shape[2] - past_window - future_window)\n","\t\t]\n","\n","print(timestamps[-1])"]},{"cell_type":"markdown","metadata":{},"source":["# Model Definition\n","\n","Baseline Graph Convolutional Network Models used for comparing our modified MTGNN. We researched various other GCNs that also capture temporal and spatial dynamics in a dataset. The following models and the research papers they are from are included below."]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:37:01.937273Z","iopub.status.busy":"2024-11-14T14:37:01.936912Z","iopub.status.idle":"2024-11-14T14:37:01.983087Z","shell.execute_reply":"2024-11-14T14:37:01.982103Z","shell.execute_reply.started":"2024-11-14T14:37:01.937240Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv, GATv2Conv\n","\n","class GCN(nn.Module):\n","\t\"\"\"\n","\tSimple two layers GCN model.\n","\t\"\"\"\n","\tdef __init__(self, in_channels: int, layer_sizes: list[int] = None, bias: bool = True, improved: bool = False):\n","\t\tsuper(GCN, self).__init__()\n","\t\tlayer_sizes = layer_sizes or [32, 32]\n","\t\tself.convs = nn.ModuleList([\n","\t\t   GCNConv(in_channels, layer_sizes[0], bias=bias, improved=improved),\n","\t\t] + [\n","\t\t   GCNConv(layer_sizes[i], layer_sizes[i + 1], bias=bias, improved=improved) for i in\n","\t\t   range(len(layer_sizes) - 1)\n","   \t\t])\n","\n","\tdef forward(self, x: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor) -> torch.tensor:\n","\t\t\"\"\"\n","\t\t:param x: The feature matrix of the graph X_t (Nodes_nb, Features_nb)\n","\t\t:param edge_index: The edge index of the graph A (2, Edges_nb)\n","\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n","\t\t:return: The hidden state of the GCN h_t (Nodes_nb, Hidden_size)\n","\t\t\"\"\"\n","\t\tfor conv in self.convs[:-1]:\n","\t\t\tx = F.leaky_relu(conv(x, edge_index, edge_weight))\n","\t\treturn self.convs[-1](x, edge_index, edge_weight)\n","        \n","class GAT(nn.Module):\n","\t\"\"\"\n","\tSimple two layers GAT model.\n","\t\"\"\"\n","\tdef __init__(self, in_channels: int, layer_sizes: list[int] = None, bias: bool = True):\n","\t\tsuper(GAT, self).__init__()\n","\t\tlayer_sizes = layer_sizes or [32, 32]\n","\t\tself.convs = nn.ModuleList([\n","\t\t   GATv2Conv(in_channels, layer_sizes[0], bias=bias, edge_dim=1),\n","\t\t] + [\n","\t\t   GATv2Conv(layer_sizes[i], layer_sizes[i + 1], bias=bias, edge_dim=1) for i in\n","\t\t   range(len(layer_sizes) - 1)\n","   \t\t])\n","\n","\tdef forward(self, x: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor) -> torch.tensor:\n","\t\t\"\"\"\n","\t\t:param x: The feature matrix of the graph X_t (Nodes_nb, Features_nb)\n","\t\t:param edge_index: The edge index of the graph A (2, Edges_nb)\n","\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n","\t\t:return: The hidden state of the GCN h_t (Nodes_nb, Hidden_size)\n","\t\t\"\"\"\n","\t\tfor conv in self.convs[:-1]:\n","\t\t\tx = F.leaky_relu(conv(x, edge_index, edge_weight))\n","\t\treturn self.convs[-1](x, edge_index, edge_weight)\n","\n","class TGCNCell(nn.Module):\n","\t\"\"\"\n","\tT-GCN Cell for one timestep, from https://arxiv.org/pdf/1811.05320.\n","\t\"\"\"\n","\tdef __init__(self, in_channels: int, hidden_size: int, use_gat: bool = True):\n","\t\tsuper(TGCNCell, self).__init__()\n","\t\tif use_gat:\n","\t\t\tself.gcn = GAT(in_channels, [hidden_size, hidden_size]).to(device)\n","\t\telse:\n","\t\t\tself.gcn = GCN(in_channels, [hidden_size, hidden_size]).to(device)\n","\t\tself.lin_u = nn.Linear(2 * hidden_size + in_channels, hidden_size)\n","\t\tself.lin_r = nn.Linear(2 * hidden_size + in_channels, hidden_size)\n","\t\tself.lin_c = nn.Linear(2 * hidden_size + in_channels, hidden_size)\n","\n","\tdef forward(self, x: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor, h: torch.tensor) -> tuple[torch.tensor, torch.tensor]:\n","\t\t\"\"\"\n","\t\t:param x: The feature matrix of the graph X_t (Nodes_nb, Features_nb)\n","\t\t:param edge_index: The edge index of the graph A (2, Edges_nb)\n","\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n","\t\t:param h: The hidden state of the GRU h_{t-1} (Nodes_nb, Hidden_size)\n","\t\t:return: The hidden state of the GRU h_t (Nodes_nb, Hidden_size)\n","\t\t\"\"\"\n","\t\tgcn_out = F.sigmoid(self.gcn(x, edge_index, edge_weight))  # f(A,X_t), Eq. 2\n","\t\tu = F.sigmoid(self.lin_u(torch.cat([x, gcn_out, h], dim=-1)))  # u_t, Eq. 3\n","\t\tr = F.sigmoid(self.lin_r(torch.cat([x, gcn_out, h], dim=-1)))  # r_t,  Eq. 4\n","\t\tc = F.tanh(self.lin_c(torch.cat([x, gcn_out, r * h], dim=-1)))  # c_t, Eq. 5\n","\n","\t\treturn u * h + (1 - u) * c  # h_t, Eq. 6\n","\n","class TGCN(nn.Module):\n","\t\"\"\"\n","\tT-GCN model from https://arxiv.org/pdf/1811.05320.\n","\t\"\"\"\n","\tdef __init__(self, in_channels: int, out_channels: int, hidden_size: int, layers_nb: int = 2, output_activation: nn.Module = None, use_gat: bool = True):\n","\t\tsuper(TGCN, self).__init__()\n","\t\tself.hidden_size = hidden_size\n","\t\tself.layers_nb = max(1, layers_nb)\n","\t\tself.cells = nn.ModuleList(\n","\t\t\t[TGCNCell(in_channels, hidden_size, use_gat=use_gat)] + [TGCNCell(hidden_size, hidden_size, use_gat=use_gat) for _ in range(self.layers_nb - 1)]\n","\t\t)\n","\t\tself.out = nn.Sequential(\n","\t\t\tnn.Linear(hidden_size, out_channels),\n","\t\t\toutput_activation if output_activation is not None else nn.Identity(),\n","\t\t)\n","\n","\tdef forward(self, x: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor) -> torch.tensor:\n","\t\t\"\"\"\n","\t\t:param x: The feature matrix of the graph X_t (Nodes_nb, Features_nb, SeqLength)\n","\t\t:param edge_index: The edge index of the graph A (2, Edges_nb)\n","\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n","\t\t:return: The output of the model (Nodes_nb, OutFeatures_nb)\n","\t\t\"\"\"\n","\t\th_prev = [\n","\t\t\ttorch.zeros(x.shape[0], self.hidden_size).to(device) for _ in range(self.layers_nb)\n","\t\t]\n","\t\tfor t in range(x.shape[-1]):\n","\t\t\th = x[:, :, t]  # h is the output of the previous GRU layer (the input features for the first layer)\n","\t\t\tfor i, cell in enumerate(self.cells):\n","\t\t\t\th = cell(h, edge_index, edge_weight, h_prev[i])\n","\t\t\t\th_prev[i] = h\n","\t\treturn self.out(h_prev[-1])\n","\n","class A3TGCN(nn.Module):\n","\t\"\"\"\n","\tA3T-GCN model from https://arxiv.org/pdf/2006.11583.\n","\t\"\"\"\n","\tdef __init__(self, in_channels: int, out_channels: int, hidden_size: int, layers_nb: int = 2, output_activation: nn.Module = None, use_gat: bool = True):\n","\t\tsuper(A3TGCN, self).__init__()\n","\t\tself.hidden_size = hidden_size\n","\t\tself.layers_nb = max(1, layers_nb)\n","\t\tself.cells = nn.ModuleList(\n","\t\t\t[TGCNCell(in_channels, hidden_size, use_gat=use_gat)] + [TGCNCell(hidden_size, hidden_size, use_gat=use_gat) for _ in range(self.layers_nb - 1)]\n","\t\t)\n","\t\tself.attention = nn.Sequential(\n","\t\t\tnn.Linear(hidden_size, 1),\n","\t\t\tnn.Softmax(dim=1),\n","\t\t)\n","\t\tnn.init.uniform_(self.attention[0].weight)\n","\t\tself.out = nn.Sequential(\n","\t\t\tnn.Linear(hidden_size, out_channels),\n","\t\t\toutput_activation if output_activation is not None else nn.Identity(),\n","\t\t)\n","\n","\tdef forward(self, x: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor) -> torch.tensor:\n","\t\t\"\"\"\n","\t\t:param x: The feature matrix of the graph X_t (Nodes_nb, Features_nb, SeqLength)\n","\t\t:param edge_index: The edge index of the graph A (2, Edges_nb)\n","\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n","\t\t:return: The output of the model (Nodes_nb, OutFeatures_nb)\n","\t\t\"\"\"\n","\t\th_prev = [\n","\t\t\ttorch.zeros(x.shape[0], self.hidden_size).to(device) for _ in range(self.layers_nb)\n","\t\t]\n","\t\th_final = torch.zeros(x.shape[0], x.shape[-1], self.hidden_size).to(device)\n","\t\tfor t in range(x.shape[-1]):\n","\t\t\th = x[:, :, t]  # h is the output of the previous GRU layer (the input features for the first layer)\n","\t\t\tfor i, cell in enumerate(self.cells):\n","\t\t\t\th = cell(h, edge_index, edge_weight, h_prev[i])\n","\t\t\t\th_prev[i] = h\n","\t\t\th_final[:, t, :] = h\n","\t\treturn self.out(F.leaky_relu(torch.sum(F.leaky_relu(h_final) * self.attention(h_final), dim=1)))\n","\n","\n","class DCGRUCell(nn.Module):\n","\t\"\"\"\n","\tDCRNN Cell for one timestep, from https://arxiv.org/pdf/1707.01926.\n","\t\"\"\"\n","\tdef __init__(self, in_channels: int, hidden_size: int, use_gat: bool = True):\n","\t\tsuper(DCGRUCell, self).__init__()\n","\t\tif use_gat:\n","\t\t\tself.gcn_r = GAT(in_channels + hidden_size, [hidden_size, hidden_size], bias=True)\n","\t\t\tself.gcn_u = GAT(in_channels + hidden_size, [hidden_size, hidden_size], bias=True)\n","\t\t\tself.gcn_c = GAT(in_channels + hidden_size, [hidden_size, hidden_size], bias=True)\n","\t\telse:\n","\t\t\tself.gcn_r = GCN(in_channels + hidden_size, [hidden_size, hidden_size], bias=True)\n","\t\t\tself.gcn_u = GCN(in_channels + hidden_size, [hidden_size, hidden_size], bias=True)\n","\t\t\tself.gcn_c = GCN(in_channels + hidden_size, [hidden_size, hidden_size], bias=True)\n","\n","\tdef forward(self, x: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor, h: torch.tensor) -> torch.tensor:\n","\t\t\"\"\"\n","\t\t:param x: The feature matrix of the graph X_t (Nodes_nb, Features_nb)\n","\t\t:param edge_index: The edge index of the graph A (2, Edges_nb)\n","\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n","\t\t:param h: The hidden state of the GRU h_{t-1} (Nodes_nb, Hidden_size)\n","\t\t:return: The hidden state of the GRU h_t (Nodes_nb, Hidden_size)\n","\t\t\"\"\"\n","\t\tx_h = torch.cat([x, h], dim=-1)\n","\t\tr = F.sigmoid(self.gcn_r(x_h, edge_index, edge_weight))\n","\t\tu = F.sigmoid(self.gcn_u(x_h, edge_index, edge_weight))\n","\t\tc = F.tanh(self.gcn_c(torch.cat([x, r * h], dim=-1), edge_index, edge_weight))\n","\t\treturn u * h + (1 - u) * c\n","\n","class DCGNN(nn.Module):\n","\t\"\"\"\n","\tDCGNN model from https://arxiv.org/pdf/1707.01926.\n","\t\"\"\"\n","\tdef __init__(self, in_channels: int, out_channels: int, hidden_size: int, layers_nb: int = 2, output_activation: nn.Module = None, use_gat: bool = True):\n","\t\tsuper(DCGNN, self).__init__()\n","\t\tself.hidden_size = hidden_size\n","\t\tself.layers_nb = max(1, layers_nb)\n","\t\tself.cells = nn.ModuleList(\n","\t\t\t[DCGRUCell(in_channels, hidden_size, use_gat=use_gat)] + [DCGRUCell(hidden_size, hidden_size, use_gat=use_gat) for _ in range(self.layers_nb - 1)]\n","\t\t)\n","\t\tself.out = nn.Sequential(\n","\t\t\tnn.Linear(hidden_size, out_channels),\n","\t\t\toutput_activation if output_activation is not None else nn.Identity(),\n","\t\t)\n","\n","\tdef forward(self, x: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor) -> torch.tensor:\n","\t\t\"\"\"\n","\t\t:param x: The feature matrix of the graph X_t (Nodes_nb, Features_nb, SeqLength)\n","\t\t:param edge_index: The edge index of the graph A (2, Edges_nb)\n","\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n","\t\t:return: The output of the model (Nodes_nb, OutFeatures_nb)\n","\t\t\"\"\"\n","\t\th_prev = [\n","\t\t\ttorch.zeros(x.shape[0], self.hidden_size).to(device) for _ in range(self.layers_nb)\n","\t\t]\n","\t\tfor t in range(x.shape[-1]):\n","\t\t\th = x[:, :, t]  # h is the output of the previous GRU layer (the input features for the first layer)\n","\t\t\tfor i, cell in enumerate(self.cells):\n","\t\t\t\th = cell(h, edge_index, edge_weight, h_prev[i])\n","\t\t\t\th_prev[i] = h\n","\t\treturn self.out(h_prev[-1])"]},{"cell_type":"markdown","metadata":{},"source":["# Training and Testing"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-11-13T20:31:24.388358Z","iopub.status.busy":"2024-11-13T20:31:24.387929Z","iopub.status.idle":"2024-11-13T20:31:24.392860Z","shell.execute_reply":"2024-11-13T20:31:24.391849Z","shell.execute_reply.started":"2024-11-13T20:31:24.388303Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:38:10.713947Z","iopub.status.busy":"2024-11-14T14:38:10.713076Z","iopub.status.idle":"2024-11-14T14:38:10.722878Z","shell.execute_reply":"2024-11-14T14:38:10.721931Z","shell.execute_reply.started":"2024-11-14T14:38:10.713908Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train dataset: 24293, Test dataset: 2700\n"]}],"source":["import torch.nn as nn\n","import torch.optim as optim\n","from torch_geometric.loader import DataLoader\n","torch.cuda.empty_cache()\n","\n","train_part = .9 # Split Data by so that first 90% is for training, and last 10% for testing\n","batch_size = 16\n","\n","train_dataset, test_dataset = timestamps[:int(train_part * len(timestamps))], timestamps[int(train_part * len(timestamps)):]\n","print(f\"Train dataset: {len(train_dataset)}, Test dataset: {len(test_dataset)}\")\n","train_dataloader, test_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True), DataLoader(test_dataset, batch_size=len(test_dataset), drop_last=True)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T17:53:01.016692Z","iopub.status.busy":"2024-11-14T17:53:01.016041Z","iopub.status.idle":"2024-11-14T17:53:01.030863Z","shell.execute_reply":"2024-11-14T17:53:01.030009Z","shell.execute_reply.started":"2024-11-14T17:53:01.016650Z"},"trusted":true},"outputs":[],"source":["from torch import nn, optim\n","from torch.utils.tensorboard import SummaryWriter\n","from torch_geometric.data import DataLoader\n","from datetime import datetime\n","from tqdm import trange\n","        \n","def test_iteration(model: nn.Module, criterion: nn.Module, test_dataloader: DataLoader, epoch: int, writer: SummaryWriter) -> None:\n","    \"\"\"\n","    Test iteration\n","    :param model: Model to test\n","    :param criterion: Loss function to use\n","    :param test_dataloader: Test data loader\n","    :param epoch: Current epoch\n","    :param writer: Tensorboard writer\n","    \"\"\"\n","    model.eval()\n","    for idx, data in enumerate(test_dataloader):\n","        data = data.to(device) \n","        out = model(data.x, data.edge_index, data.edge_weight).to(device) \n","        loss = criterion(out, data.y)\n","        writer.add_scalar(\"Loss/Test Loss\", loss.item(), epoch * len(test_dataloader) + idx)\n","\n","def train_iteration(model: nn.Module, optimizer: optim.Optimizer, pbar: trange, criterion: nn.Module, train_dataloader: DataLoader, epoch: int, writer: SummaryWriter) -> None:\n","    \"\"\"\n","    Train iteration\n","    :param model: Model to train\n","    :param optimizer: Optimizer to use (Adam, ...)\n","    :param pbar: tqdm progress bar\n","    :param criterion: Loss function to use\n","    :param train_dataloader: Train data loader\n","    :param epoch: Current epoch\n","    :param writer: Tensorboard writer\n","    :param measure_acc: Whether to measure accuracy or not (for classification tasks)\n","    \"\"\"\n","    model.train()\n","    total_loss = 0.0\n","    num_batches = len(train_dataloader)\n","    \n","    for idx, data in enumerate(train_dataloader):\n","        data = data.to(device) \n","        optimizer.zero_grad()\n","        out = model(data.x, data.edge_index, data.edge_weight)\n","        loss = criterion(out, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","        pbar.set_postfix({\"Batch\": f\"{(idx + 1) / len(train_dataloader) * 100:.1f}%\"})\n","        writer.add_scalar(\"Loss/Train Loss\", loss.item(), epoch * len(train_dataloader) + idx)\n","        \n","    average_loss = total_loss / num_batches\n","    print(f'Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {average_loss:.4f}')\n","\n","def train(model: nn.Module, optimizer: optim.Optimizer, criterion: nn.Module, train_dataloader: DataLoader, test_dataloader: DataLoader, num_epochs: int, task_title: str = \"\") -> None:\n","    \"\"\"\n","    Train function for a regression / classification model\n","    :param model: Model to train\n","    :param optimizer: Optimizer to use (Adam, ...)\n","    :param criterion: Loss function to use\n","    :param train_dataloader: Train data loader\n","    :param test_dataloader: Test data loader\n","    :param num_epochs: Number of epochs to train on the train dataset\n","    :param task_title: Title of the tensorboard run\n","    \"\"\"\n","    writer = SummaryWriter(f'runs/{task_title}_{datetime.now().strftime(\"%d_%m_%Hh%M\")}_{model.__class__.__name__}')\n","    for epoch in (pbar := trange(num_epochs, desc=\"Epochs\")):\n","        train_iteration(model, optimizer, pbar, criterion, train_dataloader, epoch, writer)\n","        test_iteration(model, criterion, test_dataloader, epoch, writer)"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T17:53:06.082350Z","iopub.status.busy":"2024-11-14T17:53:06.081620Z","iopub.status.idle":"2024-11-14T17:53:06.098116Z","shell.execute_reply":"2024-11-14T17:53:06.097225Z","shell.execute_reply.started":"2024-11-14T17:53:06.082312Z"},"trusted":true},"outputs":[],"source":["in_channels, out_channels, hidden_size, layers_nb = timestamps[0].x.shape[-2], 1, 16, 2\n","lr, weight_decay, num_epochs = 0.001, 1e-5, 16\n","\n","tgcn_no_gat_model = TGCN(in_channels, out_channels, hidden_size, layers_nb, use_gat = False).to(device)\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(tgcn_no_gat_model.parameters(), lr = lr, weight_decay = weight_decay)\n","\n","tgcn_no_gat_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T17:53:08.753436Z","iopub.status.busy":"2024-11-14T17:53:08.753034Z","iopub.status.idle":"2024-11-14T19:01:50.341977Z","shell.execute_reply":"2024-11-14T19:01:50.341036Z","shell.execute_reply.started":"2024-11-14T17:53:08.753397Z"},"trusted":true},"outputs":[],"source":["train(tgcn_no_gat_model, optimizer, criterion, train_dataloader, test_dataloader, num_epochs, \"PriceForecasting_TGCN\")\n","torch.save(tgcn_no_gat_model.state_dict(), 'tgcn_no_gat_model_epoch_16.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:53:26.474860Z","iopub.status.busy":"2024-11-14T14:53:26.474071Z","iopub.status.idle":"2024-11-14T14:53:26.490750Z","shell.execute_reply":"2024-11-14T14:53:26.489944Z","shell.execute_reply.started":"2024-11-14T14:53:26.474821Z"},"trusted":true},"outputs":[],"source":["in_channels, out_channels, hidden_size, layers_nb = timestamps[0].x.shape[-2], 1, 16, 2\n","a3tgcn_no_gat_model = A3TGCN(in_channels, out_channels, hidden_size, layers_nb, use_gat = False).to(device)\n","\n","lr, weight_decay, num_epochs = 0.001, 1e-5, 16\n","\n","criterion = nn.MSELoss()\n","optimizer_a3tgcn = optim.Adam(a3tgcn_no_gat_model.parameters(), lr=lr, weight_decay=weight_decay)\n","a3tgcn_no_gat_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T14:53:43.811053Z","iopub.status.busy":"2024-11-14T14:53:43.810658Z","iopub.status.idle":"2024-11-14T16:05:26.567746Z","shell.execute_reply":"2024-11-14T16:05:26.566787Z","shell.execute_reply.started":"2024-11-14T14:53:43.811016Z"},"trusted":true},"outputs":[],"source":["train(a3tgcn_no_gat_model, optimizer_a3tgcn, criterion, train_dataloader, test_dataloader, num_epochs, \"PriceForecasting_A3TGCN\")\n","torch.save(a3tgcn_no_gat_model.state_dict(), 'a3tgcn_no_gat_model_epoch_16.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T16:08:46.062995Z","iopub.status.busy":"2024-11-14T16:08:46.062610Z","iopub.status.idle":"2024-11-14T16:08:46.087988Z","shell.execute_reply":"2024-11-14T16:08:46.087117Z","shell.execute_reply.started":"2024-11-14T16:08:46.062957Z"},"trusted":true},"outputs":[],"source":["in_channels, out_channels, hidden_size, layers_nb = timestamps[0].x.shape[-2], 1, 16, 2\n","dcgnn_no_gat_model = DCGNN(in_channels, out_channels, hidden_size, layers_nb, use_gat = False).to(device)\n","\n","lr, weight_decay, num_epochs = 0.001, 1e-5, 16\n","\n","criterion = nn.MSELoss()\n","optimizer_dcgnn = optim.Adam(dcgnn_no_gat_model.parameters(), lr=lr, weight_decay=weight_decay)\n","dcgnn_no_gat_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T16:08:48.844775Z","iopub.status.busy":"2024-11-14T16:08:48.843904Z","iopub.status.idle":"2024-11-14T17:24:37.613225Z","shell.execute_reply":"2024-11-14T17:24:37.612252Z","shell.execute_reply.started":"2024-11-14T16:08:48.844732Z"},"trusted":true},"outputs":[],"source":["train(dcgnn_no_gat_model, optimizer_dcgnn, criterion, train_dataloader, test_dataloader, num_epochs, \"PriceForecasting_DCGNN\")\n","torch.save(dcgnn_no_gat_model.state_dict(), 'dcgnn_no_gat_model_epoch_16.pth')"]},{"cell_type":"markdown","metadata":{},"source":["# Results\n","\n","Printing Regression Error and plotting predictions against actual targets for comparison"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T16:06:38.406951Z","iopub.status.busy":"2024-11-14T16:06:38.406031Z","iopub.status.idle":"2024-11-14T16:06:38.421189Z","shell.execute_reply":"2024-11-14T16:06:38.420235Z","shell.execute_reply.started":"2024-11-14T16:06:38.406910Z"},"trusted":true},"outputs":[],"source":["from torch.nn import functional as F\n","\n","def get_regression_error(model: nn.Module, dataloader: DataLoader) -> tuple[float, float, float, float]:\n","\t\"\"\"\n","\tComputes regression errors\n","\t:param model: Model to test\n","\t:param dataloader: Dataloader to test on\n","\t:return: Mean squared error, rooted mean squared error, mean absolute error, mean relative error\n","\t\"\"\"\n","\tmse = 0\n","\trmse = 0\n","\tmae = 0\n","\tmre = 0\n","\tfor data in dataloader:\n","\t\tout = model(data.x, data.edge_index, data.edge_weight)\n","\t\tmse += F.mse_loss(out, data.y).item()\n","\t\trmse += F.mse_loss(out, data.y).sqrt().item()\n","\t\tmae += F.l1_loss(out, data.y).item()\n","\t\tmre += (F.l1_loss(out, data.y) / data.y.abs().mean()).item()\n","\treturn mse / len(dataloader), rmse / len(dataloader), mae / len(dataloader), mre / len(dataloader)\n","\n","def plot_regression_all(model: nn.Module, data: Data, all_data: pd.DataFrame, title: str = None) -> None:\n","    \"\"\"\n","    Plot graphs for all currencies in the regression model.\n","    :param model: Model to test\n","    :param data: Data to test on\n","    :param all_data: DataFrame containing all data with tickers as index level 0\n","    :param title: Title of the plot\n","    \"\"\"\n","    model.eval()\n","    out = model(data.x, data.edge_index, data.edge_weight)\n","\n","    preds = out.reshape(len(data.ptr) - 1, -1).cpu()\n","    target = data.y.reshape(len(data.ptr) - 1, -1).cpu()\n","\n","    # Extract tickers from the DataFrame\n","    tickers = all_data.index.levels[0].tolist()\n","    \n","    num_currencies = len(tickers)\n","    num_cols = 4\n","    num_rows = (num_currencies + num_cols - 1) // num_cols\n","\n","    fig, axs = plt.subplots(num_rows, num_cols, figsize=(20, num_rows * 4))\n","    fig.suptitle(title)\n","    axs = axs.flatten()\n","\n","    for idx in range(num_currencies):\n","        ax = axs[idx]\n","        ax.plot(target[:, idx].detach().cpu().numpy(), label=\"Real\")\n","        ax.plot(preds[:, idx].detach().cpu().numpy(), label=\"Predicted\")\n","        ax.set_title(f\"Currency: {tickers[idx]}\")\n","        ax.legend()\n","\n","    # Hide any unused subplots\n","    for j in range(num_currencies, num_rows * num_cols):\n","        axs[j].axis('off')\n","\n","    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to include title\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## TCGN Model Results (No GAT)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T19:12:18.209153Z","iopub.status.busy":"2024-11-14T19:12:18.208215Z","iopub.status.idle":"2024-11-14T19:15:26.491125Z","shell.execute_reply":"2024-11-14T19:15:26.490119Z","shell.execute_reply.started":"2024-11-14T19:12:18.209101Z"},"trusted":true},"outputs":[],"source":["# TCGN Model Results (No Attention Mechanism)\n","mse, rmse, mae, mre = get_regression_error(tgcn_no_gat_model, train_dataloader)\n","print(f\"TCGN w/o GAT Train MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, MRE: {mre:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T20:36:21.157850Z","iopub.status.busy":"2024-11-14T20:36:21.157095Z","iopub.status.idle":"2024-11-14T20:36:21.484199Z","shell.execute_reply":"2024-11-14T20:36:21.482708Z","shell.execute_reply.started":"2024-11-14T20:36:21.157805Z"},"trusted":true},"outputs":[],"source":["plot_regression_all(tgcn_no_gat_model, next(iter(train_dataloader)), all_data, \"TGCN Train Plots\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-13T21:50:02.524734Z","iopub.status.busy":"2024-11-13T21:50:02.524301Z","iopub.status.idle":"2024-11-13T21:50:03.229347Z","shell.execute_reply":"2024-11-13T21:50:03.228217Z","shell.execute_reply.started":"2024-11-13T21:50:02.524695Z"},"trusted":true},"outputs":[],"source":["# Test Results\n","A3TGCN, rmse, mae, mre = get_regression_error(tgcn_no_gat_model, test_dataloader)\n","print(f\"Test MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, MRE: {mre:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-13T21:50:28.175570Z","iopub.status.busy":"2024-11-13T21:50:28.175077Z","iopub.status.idle":"2024-11-13T21:50:39.253235Z","shell.execute_reply":"2024-11-13T21:50:39.252130Z","shell.execute_reply.started":"2024-11-13T21:50:28.175529Z"},"trusted":true},"outputs":[],"source":["plot_regression_all(tgcn_no_gat_model, next(iter(test_dataloader)), all_data, \"TGCN Test Plots\")"]},{"cell_type":"markdown","metadata":{},"source":["## A3TCGN Model Results (Without GAT)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train Results (skip as it takes a minute)\n","mse, rmse, mae, mre = get_regression_error(a3tgcn_no_gat_model, train_dataloader)\n","print(f\"Train MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, MRE: {mre:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T16:06:54.954518Z","iopub.status.busy":"2024-11-14T16:06:54.954135Z","iopub.status.idle":"2024-11-14T16:07:04.459682Z","shell.execute_reply":"2024-11-14T16:07:04.458734Z","shell.execute_reply.started":"2024-11-14T16:06:54.954482Z"},"trusted":true},"outputs":[],"source":["plot_regression_all(a3tgcn_no_gat_model, next(iter(train_dataloader)), all_data, \"A3TGCN Train Plots\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T16:07:10.892892Z","iopub.status.busy":"2024-11-14T16:07:10.892145Z","iopub.status.idle":"2024-11-14T16:07:11.623952Z","shell.execute_reply":"2024-11-14T16:07:11.622970Z","shell.execute_reply.started":"2024-11-14T16:07:10.892850Z"},"trusted":true},"outputs":[],"source":["# Test Results\n","mse, rmse, mae, mre = get_regression_error(a3tgcn_no_gat_model, test_dataloader)\n","print(f\"Test MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, MRE: {mre:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T16:07:13.876916Z","iopub.status.busy":"2024-11-14T16:07:13.876066Z","iopub.status.idle":"2024-11-14T16:07:23.878858Z","shell.execute_reply":"2024-11-14T16:07:23.877846Z","shell.execute_reply.started":"2024-11-14T16:07:13.876877Z"},"trusted":true},"outputs":[],"source":["plot_regression_all(a3tgcn_no_gat_model, next(iter(test_dataloader)), all_data, \"A3TGCN Test Plots\")"]},{"cell_type":"markdown","metadata":{},"source":["## DCGNN Results (No GAT)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train Results (skip as it takes a minute)\n","mse, rmse, mae, mre = get_regression_error(dcgnn_no_gat_model, train_dataloader)\n","print(f\"Train MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, MRE: {mre:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T17:37:33.658764Z","iopub.status.busy":"2024-11-14T17:37:33.657999Z","iopub.status.idle":"2024-11-14T17:37:43.453870Z","shell.execute_reply":"2024-11-14T17:37:43.452982Z","shell.execute_reply.started":"2024-11-14T17:37:33.658720Z"},"trusted":true},"outputs":[],"source":["plot_regression_all(dcgnn_no_gat_model, next(iter(train_dataloader)), all_data, \"DCGNN Train Plots\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T17:37:50.720334Z","iopub.status.busy":"2024-11-14T17:37:50.719892Z","iopub.status.idle":"2024-11-14T17:37:51.665719Z","shell.execute_reply":"2024-11-14T17:37:51.664764Z","shell.execute_reply.started":"2024-11-14T17:37:50.720292Z"},"trusted":true},"outputs":[],"source":["# Test Results\n","mse, rmse, mae, mre = get_regression_error(dcgnn_no_gat_model, test_dataloader)\n","print(f\"Test MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, MRE: {mre:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-14T17:37:53.840977Z","iopub.status.busy":"2024-11-14T17:37:53.840574Z","iopub.status.idle":"2024-11-14T17:38:04.822321Z","shell.execute_reply":"2024-11-14T17:38:04.821455Z","shell.execute_reply.started":"2024-11-14T17:37:53.840929Z"},"trusted":true},"outputs":[],"source":["plot_regression_all(dcgnn_no_gat_model, next(iter(test_dataloader)), all_data, \"DCGNN Test Plots\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":6052833,"sourceId":9862047,"sourceType":"datasetVersion"},{"datasetId":6070034,"sourceId":9884893,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
